{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python385jvsc74a57bd0082e9a3bcad0a290d0001e938aa60b99250c6c2ef33a923c00b70f9826caf4b7",
   "display_name": "Python 3.8.5 64-bit"
  },
  "metadata": {
   "interpreter": {
    "hash": "082e9a3bcad0a290d0001e938aa60b99250c6c2ef33a923c00b70f9826caf4b7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Recommendation Systems Exhibition"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages used throughout\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
    "\n",
    "from data import import_data \n",
    "from methods import (utils, losses, matrix_factorization, AutoRec,   \n",
    "    neural_collaborative_filtering, sequence_aware)"
   ]
  },
  {
   "source": [
    "## Datasets"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### Movielens Data"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import data\n",
    "names = [\"user_id\", \"item_id\", \"rating\", \"timestamp\"]\n",
    "data = pd.read_csv(\"data/u.data\", delimiter='\\t', names = names, engine = \"python\")\n",
    "num_users = data.user_id.unique().shape[0]\n",
    "num_items = data.item_id.unique().shape[0]"
   ]
  },
  {
   "source": [
    "## Explicit Models (with MovieLens)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### Matrix Factorization"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtain the data\n",
    "num_users, num_items, train_iter, test_iter = import_data.split_and_load_ml100k(data,\n",
    "    num_users, num_items, test_ratio = 0.1, batch_size=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define evaluator\n",
    "def evaluator(net, test_iter):\n",
    "    rmse_list = []\n",
    "    for idx, (users, items, ratings) in enumerate(test_iter):\n",
    "        r_hat = net(users, items)\n",
    "        rmse_value = torch.sqrt(((r_hat - ratings)**2).mean())\n",
    "        rmse_list.append(float(rmse_value))\n",
    "\n",
    "    return np.mean(np.array(rmse_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare model\n",
    "lr, num_epochs, wd = 0.002, 20, 1e-5\n",
    "\n",
    "mf_net = matrix_factorization.MF(30, num_users, num_items)\n",
    "optimizer = optim.Adam(mf_net.parameters(), lr = lr, weight_decay = wd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train and evaluate model\n",
    "rmse_list = []\n",
    "loss_list = []\n",
    "for epoch in range(num_epochs):\n",
    "    total_loss, num_samples = 0, 0\n",
    "\n",
    "    # Train each batch\n",
    "    mf_net.train()\n",
    "    for i, (users, items, ratings) in enumerate(train_iter):\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        predictions = mf_net(users, items)\n",
    "        output = ((predictions - ratings)**2).mean()\n",
    "        output.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += output\n",
    "        num_samples += users.shape[0]\n",
    "    \n",
    "    # Evaluate\n",
    "    mf_net.eval()\n",
    "    rmse = evaluator(mf_net, test_iter)\n",
    "    rmse_list.append(rmse)\n",
    "    loss_list.append(total_loss/num_samples)\n",
    "\n",
    "    print(f\"Epoch {epoch}:\\n\\tloss = {total_loss/num_samples}\\n\\trmse = {rmse}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize\n",
    "fig, ax = plt.subplots(2)\n",
    "fig.suptitle(f\"Matrix Factorization Test over {num_epochs} Epochs\")\n",
    "\n",
    "x_vals = list(range(1, num_epochs + 1))\n",
    "ax[0].plot(x_vals, rmse_list, label = \"RMSE\", color = \"blue\")\n",
    "ax[0].set_ylabel(\"RMSE\")\n",
    "ax[0].set_xticks(x_vals[::2])\n",
    "ax[0].legend()\n",
    "\n",
    "ax[1].plot(x_vals, loss_list, label = \"Loss\", color = \"green\")\n",
    "ax[1].set_ylabel(\"Loss\")\n",
    "ax[1].set_xlabel(\"Epoch\")\n",
    "ax[1].set_xticks(x_vals[::2])\n",
    "ax[1].legend()"
   ]
  },
  {
   "source": [
    "### AutoRec"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtain the data\n",
    "train_data, test_data = import_data.split_data_ml100k(data, num_users, num_items)\n",
    "\n",
    "_, _, _, train_inter_matrix = import_data.load_data_ml100k(train_data, num_users, num_items)\n",
    "_, _, _, test_inter_matrix = import_data.load_data_ml100k(test_data, num_users, num_items)\n",
    "\n",
    "train_inter_tensor = torch.from_numpy(train_inter_matrix).to(torch.float)\n",
    "test_inter_tensor = torch.from_numpy(test_inter_matrix).to(torch.float)\n",
    "\n",
    "train_iter = DataLoader(train_inter_tensor, shuffle = True, batch_size = 256,\n",
    "    num_workers = 4)\n",
    "test_iter = DataLoader(test_inter_tensor, shuffle = False, batch_size = 1024,\n",
    "    num_workers = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define evaluator\n",
    "def evaluator(network, test_iter):\n",
    "    rmse_list = []\n",
    "    for idx, users_ratings in enumerate(test_iter):\n",
    "        recons = network(users_ratings)\n",
    "        rmse_value = torch.sqrt(\n",
    "            ((torch.sign(users_ratings) * recons - users_ratings)**2).mean())\n",
    "        rmse_list.append(float(rmse_value))\n",
    "\n",
    "    return np.mean(np.array(rmse_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare model\n",
    "lr, num_epochs, wd = 0.002, 25, 1e-5\n",
    "\n",
    "autorec_net = AutoRec(500, num_users)\n",
    "optimizer = optim.Adam(autorec_net.parameters(), lr = lr, weight_decay=wd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train and evaluate model\n",
    "rmse_list = []\n",
    "loss_list = []\n",
    "for epoch in range(num_epochs):\n",
    "    total_loss, num_samples = 0, 0\n",
    "\n",
    "    # Train each batch\n",
    "    autorec_net.train()\n",
    "    for i, user_ratings in enumerate(train_iter):\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        predictions = autorec_net(user_ratings)\n",
    "        output = ((predictions - user_ratings)**2).mean()\n",
    "        output.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += output\n",
    "        num_samples += user_ratings.shape[0]\n",
    "    \n",
    "    # Evaluate\n",
    "    autorec_net.eval()\n",
    "    rmse = evaluator(autorec_net, test_iter)\n",
    "    rmse_list.append(rmse)\n",
    "    loss_list.append(total_loss/num_samples)\n",
    "\n",
    "    print(f\"Epoch {epoch}:\\n\\tloss = {total_loss/num_samples}\\n\\trmse = {rmse}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize\n",
    "fig, ax = plt.subplots(2)\n",
    "fig.suptitle(f\"AutoRec Test over {num_epochs} Epochs\")\n",
    "\n",
    "x_vals = list(range(1, num_epochs + 1))\n",
    "ax[0].plot(x_vals, rmse_list, label = \"RMSE\", color = \"blue\")\n",
    "ax[0].set_ylabel(\"RMSE\")\n",
    "ax[0].set_xticks(x_vals[::2])\n",
    "ax[0].legend()\n",
    "\n",
    "ax[1].plot(x_vals, loss_list, label = \"Loss\", color = \"green\")\n",
    "ax[1].set_ylabel(\"Loss\")\n",
    "ax[1].set_xlabel(\"Epoch\")\n",
    "ax[1].set_xticks(x_vals[::2])\n",
    "ax[1].legend()"
   ]
  },
  {
   "source": [
    "## Implicit Models (with MovieLens)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define metrics\n",
    "def hit_and_auc(rankedlist, test_item, k):\n",
    "    test_item = int(test_item)\n",
    "    hits_k = test_item in rankedlist[:k]\n",
    "    hits_all = [(idx, val) for idx, val in enumerate(rankedlist) if int(val) == test_item]\n",
    "\n",
    "    max_num = len(rankedlist) - 1\n",
    "    auc = 1.0 * (max_num - hits_all[0][0]) / \\\n",
    "        max_num if len(hits_all) > 0 else 0\n",
    "    return hits_k, auc"
   ]
  },
  {
   "source": [
    "## NeuMF"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare Dataset\n",
    "batch_size = 1024\n",
    "train_data, test_data = import_data.split_data_ml100k(data, num_users,\n",
    "    num_items,'seq-aware')\n",
    "\n",
    "# Training data\n",
    "users_train, items_train, _, interactions = import_data.load_data_ml100k(\n",
    "    train_data, num_users, num_items, feedback=\"implicit\")\n",
    "train_dataset = neural_collaborative_filtering.PRDataset(users_train, items_train, \n",
    "    interactions, num_items)\n",
    "train_iter = DataLoader(train_dataset, batch_size = batch_size, shuffle = True,\n",
    "    num_workers = 4)\n",
    "\n",
    "# Test data\n",
    "_, _, _, test_interactions = import_data.load_data_ml100k(test_data, num_users, num_items,\n",
    "    feedback=\"implicit\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define evaluator\n",
    "def evaluate_ranking_bpr(net, test_input, interactions, num_users, num_items):\n",
    "    ranked_list, ranked_items, hit_rate, auc = {}, {}, [], []\n",
    "    all_items = set([i for i in range(num_items)])\n",
    "    for u in range(num_users):\n",
    "        neg_items = list(all_items - set(interactions[u]))\n",
    "        user_ids, item_ids, scores = [], [], []\n",
    "        [item_ids.append(i) for i in neg_items]\n",
    "        [user_ids.append(u) for _ in neg_items]\n",
    "        test_dataset = TensorDataset(torch.from_numpy(np.array(user_ids)),    \n",
    "            torch.from_numpy(np.array(item_ids)))\n",
    "        test_data_iter = DataLoader(test_dataset, shuffle=False, batch_size=1024)\n",
    "\n",
    "        for _, (user_idxs, item_idxs) in enumerate(test_data_iter):\n",
    "            scores.extend(list(net(user_idxs, item_idxs).detach().numpy()))\n",
    "        item_scores = list(zip(item_ids, scores))\n",
    "\n",
    "        ranked_list[u] = sorted(item_scores, key=lambda t: t[1], reverse=True)\n",
    "        ranked_items[u] = [r[0] for r in ranked_list[u]]\n",
    "        \n",
    "        temp = hit_and_auc(ranked_items[u], test_input[u][0], 50)\n",
    "        hit_rate.append(temp[0])\n",
    "        auc.append(temp[1])\n",
    "    return np.mean(np.array(hit_rate)), np.mean(np.array(auc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define weight initializer\n",
    "def weights_init(module):\n",
    "    if isinstance(module, nn.Embedding) or isinstance(module, nn.Linear):\n",
    "        nn.init.normal_(module.weight, std=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and initialize model\n",
    "lr, num_epochs, wd = 0.01, 10, 1e-5\n",
    "\n",
    "neuMF_net = neural_collaborative_filtering.NeuMF(10, num_users, num_items,\n",
    "    nums_hiddens=[10, 10, 10])\n",
    "neuMF_net.apply(weights_init)\n",
    "loss = losses.BPR_Loss\n",
    "optimizer = optim.Adam(neuMF_net.parameters(), lr = lr, weight_decay=wd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train and evaluate the model\n",
    "hit_rate_list = []\n",
    "auc_list = []\n",
    "for epoch in range(num_epochs):\n",
    "    accumulator, l = utils.Accumulator(2), 0.\n",
    "\n",
    "    # Train each batch\n",
    "    neuMF_net.train()\n",
    "    for i, (user_idxs, item_idxs, neg_items) in enumerate(train_iter):\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        p_pos = neuMF_net(user_idxs, item_idxs)\n",
    "        p_neg = neuMF_net(user_idxs, neg_items)\n",
    "\n",
    "        total_loss = loss(p_pos, p_neg)\n",
    "        total_loss.backward()\n",
    "        optimizer.step()\n",
    "        accumulator.add(total_loss, user_idxs.shape[0])\n",
    "\n",
    "    # Evaluate\n",
    "    neuMF_net.eval()\n",
    "    hit_rate, auc = evaluate_ranking_bpr(neuMF_net, test_interactions, interactions, \n",
    "        num_users, num_items)\n",
    "    hit_rate_list.append(hit_rate)\n",
    "    auc_list.append(auc)\n",
    "\n",
    "    print(f\"Epoch {epoch}:\\n\\tloss = {accumulator[0]/accumulator[1]}\\n\\thit_rate = {hit_rate}\\n\\tauc = {auc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize\n",
    "x = list(range(1, num_epochs + 1))\n",
    "plt.scatter(x, auc_list, label = \"AUC\")\n",
    "plt.scatter(x, hit_rate_list, label = \"Hit Rate\")\n",
    "plt.title(\"HR and AUC over Epoch of MF\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.legend(loc = \"lower right\")\n",
    "plt.xticks(x[0::2])\n",
    "plt.ylim((0, 1))"
   ]
  },
  {
   "source": [
    "## Caser"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare Dataset\n",
    "TARGET_NUM, L, batch_size = 1, 5, 4096\n",
    "train_data, test_data = import_data.split_data_ml100k(data, num_users, num_items,\n",
    "                                                        'seq-aware')\n",
    "\n",
    "# Training Data\n",
    "users_train, items_train, _, candidates = import_data.load_data_ml100k(\n",
    "    train_data, num_users, num_items, feedback=\"implicit\")\n",
    "train_seq_data = sequence_aware.SeqDataset(users_train, items_train, L, num_users,\n",
    "                                            num_items, candidates)\n",
    "train_iter = DataLoader(train_seq_data, batch_size=batch_size, shuffle=True,\n",
    "                        num_workers=4)\n",
    "\n",
    "# Test Data\n",
    "_, _, _, test_iter = import_data.load_data_ml100k(\n",
    "    test_data, num_users, num_items, feedback=\"implicit\")\n",
    "test_seq_iter = train_seq_data.test_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define evaluator\n",
    "def evaluate_ranking_bpr(net, test_input, test_seq_iter, interactions, num_users, num_items):\n",
    "    ranked_list, ranked_items, hit_rate, auc = {}, {}, [], []\n",
    "    all_items = set([i for i in range(num_items)])\n",
    "    for u in range(num_users):\n",
    "        neg_items = list(all_items - set(interactions[u]))\n",
    "        user_ids, item_ids, scores = [], [], []\n",
    "        [item_ids.append(i) for i in neg_items]\n",
    "        [user_ids.append(u) for _ in neg_items]\n",
    "        test_dataset = TensorDataset(torch.from_numpy(np.array(user_ids)).type(torch.long),\n",
    "                                        torch.from_numpy(np.array(item_ids)).type(torch.long),\n",
    "                                        torch.from_numpy(np.array(test_seq_iter[user_ids, :])).type(torch.long))\n",
    "        test_data_iter = DataLoader(\n",
    "            test_dataset, shuffle=False, batch_size=1024)\n",
    "\n",
    "        for i, (user_idxs, item_idxs, seq) in enumerate(test_data_iter):\n",
    "            scores.extend(\n",
    "                list(net(user_idxs, seq, item_idxs).detach().numpy()))\n",
    "        item_scores = list(zip(item_ids, scores))\n",
    "\n",
    "        ranked_list[u] = sorted(\n",
    "            item_scores, key=lambda t: t[1], reverse=True)\n",
    "        ranked_items[u] = [r[0] for r in ranked_list[u]]\n",
    "\n",
    "        temp = hit_and_auc(ranked_items[u], test_input[u][0], 50)\n",
    "        hit_rate.append(temp[0])\n",
    "        auc.append(temp[1])\n",
    "    return np.mean(np.array(hit_rate)), np.mean(np.array(auc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Weight initializer\n",
    "def weights_init(module):\n",
    "    if (isinstance(module, nn.Embedding) or isinstance(module, nn.Linear)\n",
    "            or isinstance(module, nn.Conv2d)):\n",
    "        nn.init.normal_(module.weight, std=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and initialize model\n",
    "lr, num_epochs, wd = 0.04, 10, 1e-5\n",
    "\n",
    "caser_net = sequence_aware.Caser(10, num_users, num_items, L)\n",
    "caser_net.apply(weights_init)\n",
    "loss = losses.BPR_Loss\n",
    "optimizer = optim.Adam(caser_net.parameters(), lr = lr, weight_decay=wd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train and evaluate the model\n",
    "hit_rate_list = []\n",
    "auc_list = []\n",
    "for epoch in range(num_epochs):\n",
    "    accumulator, l = utils.Accumulator(2), 0.\n",
    "\n",
    "    # Train each batch\n",
    "    caser_net.train()\n",
    "    for i, (user_idxs, seq, pos_tgts, neg_tgts) in enumerate(train_iter):\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        user_idxs = user_idxs.type(torch.long)\n",
    "        seq = seq.type(torch.long)\n",
    "        pos_tgts = pos_tgts.type(torch.long)\n",
    "        neg_tgts = neg_tgts.type(torch.long)\n",
    "\n",
    "        p_pos = caser_net(user_idxs, seq, pos_tgts)\n",
    "        p_neg = caser_net(user_idxs, seq, neg_tgts)\n",
    "\n",
    "        total_loss = loss(p_pos, p_neg)\n",
    "        total_loss.backward()\n",
    "        optimizer.step()\n",
    "        accumulator.add(total_loss, user_idxs.shape[0])\n",
    "\n",
    "    # Evaluate\n",
    "    caser_net.eval()\n",
    "    hit_rate, auc = evaluate_ranking_bpr(\n",
    "        caser_net, test_iter, test_seq_iter, candidates, num_users, num_items)\n",
    "    hit_rate_list.append(hit_rate)\n",
    "    auc_list.append(auc)\n",
    "\n",
    "    print(\n",
    "        f\"Epoch {epoch}:\\n\\tloss = {accumulator[0]/accumulator[1]}\\n\\thit_rate = {hit_rate}\\n\\tauc = {auc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize\n",
    "x = list(range(1, num_epochs + 1))\n",
    "plt.scatter(x, auc_list, label = \"AUC\")\n",
    "plt.scatter(x, hit_rate_list, label = \"Hit Rate\")\n",
    "plt.title(\"HR and AUC over Epoch of Caser\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.legend(loc = \"lower right\")\n",
    "plt.xticks(x[0::2])\n",
    "plt.ylim((0, 1))"
   ]
  }
 ]
}